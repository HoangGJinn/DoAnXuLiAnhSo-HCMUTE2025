
import streamlit as st
import numpy as np
import cv2 as cv
import joblib
from pathlib import Path
import time
from PIL import Image


FACE_MODEL_DIR = Path(__file__).parent / 'Source' / 'KhuonMat'
SVM_MODEL_PATH = FACE_MODEL_DIR / 'svc.pkl'
DETECTOR_MODEL_PATH = FACE_MODEL_DIR / 'face_detection_yunet_2023mar.onnx'
RECOGNIZER_MODEL_PATH = FACE_MODEL_DIR / 'face_recognition_sface_2021dec.onnx'

MY_DICT = ['Duy cute','Giap Xo', 'Hung Rom' ,'Tai gay', 'Vinh 30cm']
COLORS = [(0, 255, 0), (255, 200, 200), (220, 220, 255), (255, 255, 0), (0, 255, 255)]

@st.cache_resource
def load_svm_model(path):
    try:
        model = joblib.load(path)
        return model
    except FileNotFoundError:
        st.error(f"SVM model not found at {path}")
        return None
    except Exception as e:
        st.error(f"Error loading SVM model: {e}")
        return None

@st.cache_resource
def load_face_detector(model_path, input_size=(320, 320), score_threshold=0.9, nms_threshold=0.3, top_k=5000):
    model_path_str = str(model_path)
    if not Path(model_path_str).is_file():
         st.error(f"Face Detector model file not found at {model_path_str}")
         return None
    try:
        detector = cv.FaceDetectorYN.create(
            model_path_str, "", input_size, score_threshold, nms_threshold, top_k
        )
        return detector
    except Exception as e:
        st.error(f"Error loading Face Detector model from {model_path_str}: {e}")
        return None

@st.cache_resource
def load_face_recognizer(model_path):
    model_path_str = str(model_path)
    if not Path(model_path_str).is_file():
         st.error(f"Face Recognizer model file not found at {model_path_str}")
         return None
    try:
        recognizer = cv.FaceRecognizerSF.create(model_path_str, "")
        return recognizer
    except Exception as e:
        st.error(f"Error loading Face Recognizer model from {model_path_str}: {e}")
        return None

def process_video_stream(video_source):
    st.info(f"B·∫Øt ƒë·∫ßu process_video_stream v·ªõi ngu·ªìn: {video_source}")

    # --- Load Models ---
    # T·∫£i tr∆∞·ªõc khi t·∫°o UI ƒë·ªÉ ƒë·∫£m b·∫£o ch√∫ng s·∫µn s√†ng
    # C√°c h√†m cache s·∫Ω tr·∫£ v·ªÅ ngay n·∫øu ƒë√£ t·∫£i r·ªìi
    svc = load_svm_model(SVM_MODEL_PATH)
    detector = load_face_detector(DETECTOR_MODEL_PATH)
    recognizer = load_face_recognizer(RECOGNIZER_MODEL_PATH)

    # Ki·ªÉm tra xem t·∫•t c·∫£ model/resource ƒë√£ t·∫£i th√†nh c√¥ng ch∆∞a
    if not all([svc, detector, recognizer]):
        st.error("Kh√¥ng th·ªÉ t·∫£i t·∫•t c·∫£ models/resources c·∫ßn thi·∫øt. Vui l√≤ng ki·ªÉm tra l·∫°i ƒë∆∞·ªùng d·∫´n v√† file.")
        st.stop()

    st.success("T·∫•t c·∫£ models v√† resources ƒë√£ s·∫µn s√†ng.")

    # --- T·∫°o UI sau khi ch·∫Øc ch·∫Øn model ƒë√£ c√≥ ---
    frame_window = st.image([])
    stop_button = st.button('Stop', key=f'stop_{video_source}')

    # Initialize stop state if not present
    # S·ª≠ d·ª•ng key c·ª• th·ªÉ ƒë·ªÉ tr√°nh xung ƒë·ªôt n·∫øu h√†m n√†y ƒë∆∞·ª£c g·ªçi nhi·ªÅu l·∫ßn v·ªõi ngu·ªìn kh√°c nhau
    session_key_stop = f'stop_processing_{video_source}'
    if session_key_stop not in st.session_state:
        st.session_state[session_key_stop] = False

    if stop_button:
        st.session_state[session_key_stop] = True
        st.info("ƒê√£ nh·∫•n n√∫t Stop.")

    if st.session_state[session_key_stop]:
        st.warning("ƒêang ·ªü tr·∫°ng th√°i d·ª´ng.")
    else:
         st.info("Tr·∫°ng th√°i: ƒêang ch·∫°y.")

    # --- M·ªü Video Capture ---
    st.info(f"ƒêang m·ªü VideoCapture cho ngu·ªìn: {video_source}...")
    cap = cv.VideoCapture(video_source)
    time.sleep(1) # Ch·ªù m·ªôt ch√∫t ƒë·ªÉ camera/file c√≥ th·ªùi gian kh·ªüi t·∫°o

    if not cap.isOpened():
        st.error(f"!!! Kh√¥ng th·ªÉ m·ªü ngu·ªìn video: {video_source}. H√£y ki·ªÉm tra camera ho·∫∑c ƒë∆∞·ªùng d·∫´n file.")
        st.stop() # D·ª´ng h·∫≥n n·∫øu kh√¥ng m·ªü ƒë∆∞·ª£c video
    else:
        st.success(f"ƒê√£ m·ªü th√†nh c√¥ng ngu·ªìn video: {video_source}")

    # Input size c·ªßa detector
    frame_width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc frame h·ª£p l·ªá
    if frame_width <= 0 or frame_height <= 0:
        st.error(f"K√≠ch th∆∞·ªõc video kh√¥ng h·ª£p l·ªá: {frame_width}x{frame_height}. Ki·ªÉm tra l·∫°i ngu·ªìn video.")
        cap.release()
        st.stop()
    try:
         detector.setInputSize([frame_width, frame_height])
         st.info(f"ƒê√£ ƒë·∫∑t InputSize cho detector: {frame_width}x{frame_height}")
    except Exception as e:
         st.error(f"L·ªói khi ƒë·∫∑t InputSize cho detector: {e}")
         cap.release()
         st.stop()


    tm = cv.TickMeter()
    frame_count = 0 # ƒê·∫øm s·ªë frame ƒë√£ ƒë·ªçc

    # --- Main Loop ---
    while cap.isOpened():
        # Ki·ªÉm tra tr·∫°ng th√°i d·ª´ng ngay ƒë·∫ßu v√≤ng l·∫∑p
        if st.session_state.get(session_key_stop, False):
            st.info("Ph√°t hi·ªán tr·∫°ng th√°i d·ª´ng trong v√≤ng l·∫∑p.")
            break # Tho√°t v√≤ng l·∫∑p

        has_frame, frame = cap.read()
        frame_count += 1

        if not has_frame:
            st.warning(f"Kh√¥ng th·ªÉ ƒë·ªçc th√™m khung h√¨nh (ƒë√£ ƒë·ªçc {frame_count} frames). K·∫øt th√∫c lu·ªìng.")
            st.session_state[session_key_stop] = True # ƒê·∫∑t tr·∫°ng th√°i d·ª´ng khi h·∫øt video
            break

        if frame is None or frame.size == 0:
             st.warning(f"ƒê·ªçc ƒë∆∞·ª£c frame nh∆∞ng frame tr·ªëng ·ªü frame th·ª© {frame_count}.")
             continue # B·ªè qua frame l·ªói n√†y

        # --- Ch·ªâ x·ª≠ l√Ω v√† hi·ªÉn th·ªã n·∫øu kh√¥ng ·ªü tr·∫°ng th√°i d·ª´ng ---
        if not st.session_state[session_key_stop]:
            # Copy frame ƒë·ªÉ v·∫Ω
            display_frame = frame.copy()

            tm.start()
            faces = detector.detect(display_frame)
            tm.stop()

            # --- Process Detected Faces ---
            if faces[1] is not None:
                 for idx,face in enumerate(faces[1][:5]):
                     try:
                         face_align = recognizer.alignCrop(frame, face)  # D√πng frame g·ªëc ƒë·ªÉ align
                         face_feature = recognizer.feature(face_align)

                         test_predict = svc.predict(face_feature)
                         result = "Error"
                         color = (0, 0, 0)
                         confidence_threshold = 0.1  # Ng∆∞·ª°ng tin c·∫≠y

                         if hasattr(svc, "decision_function"):
                             try:
                                 # T√≠nh ƒëi·ªÉm tin c·∫≠y l·ªõn nh·∫•t
                                 confidence_score = np.max(svc.decision_function(face_feature))

                                 if confidence_score < confidence_threshold:
                                     result = "Cannot Recognize!"
                                     color = (128, 128, 128)  # M√†u x√°m
                                 # N·∫øu ƒë·ªß tin c·∫≠y, ki·ªÉm tra index v√† l·∫•y t√™n/m√†u
                                 elif 0 <= test_predict[0] < len(MY_DICT):
                                     result = MY_DICT[test_predict[0]]
                                     color = COLORS[test_predict[0]]
                                 else:
                                     result = "Unknown Index"
                                     color = (0, 0, 255)  # M√†u ƒë·ªè cho l·ªói index
                             except Exception as e_conf:
                                 print(f"Error calculating/using confidence score: {e_conf}")
                                 result = "Confidence Error"
                                 color = (0, 0, 255)  # M√†u ƒë·ªè

                         else:  # Tr∆∞·ªùng h·ª£p model kh√¥ng c√≥ decision_function
                             st.warning("SVM model does not have decision_function. Using index check only.")
                             if 0 <= test_predict[0] < len(MY_DICT):
                                 result = MY_DICT[test_predict[0]]
                                 color = COLORS[test_predict[0]]
                             else:
                                 result = "Unknown"
                                 color = (0, 0, 0)  # unknown th√¨ ƒëen

                         coords = face[:4].astype(np.int32)
                         x1, y1, w, h = coords[0], coords[1], coords[2], coords[3]
                         x2, y2 = x1 + w, y1 + h
                         cv.rectangle(display_frame, (x1, y1), (x2, y2), color, 2)
                         text_y = y1 - 10 if y1 > 10 else y1 + 15

                         # Get text size.
                         text_size = cv.getTextSize(result, cv.FONT_HERSHEY_SIMPLEX, 0.7, 1)
                         dim, baseline = text_size[0], text_size[1]
                         cv.rectangle(display_frame, (x1 - 5, text_y + 10), (x1 + dim[0], text_y + baseline - 35), color,
                                      cv.FILLED)

                         cv.putText(display_frame, result, (x1, text_y), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 1)

                     except Exception as e:
                         pass

            # Draw FPS
            cv.putText(display_frame, f'FPS: {tm.getFPS():.2f}', (5, 20), cv.FONT_HERSHEY_SIMPLEX,
                       0.6, (0, 255, 0), 3)

            frame_window.image(display_frame, channels='BGR')

    # --- Cleanup ---
    st.info("K·∫øt th√∫c v√≤ng l·∫∑p x·ª≠ l√Ω.")
    if cap.isOpened():
        cap.release()
        st.info("ƒê√£ gi·∫£i ph√≥ng VideoCapture.")
    # Reset stop state for next interaction
    if session_key_stop in st.session_state:
        st.session_state[session_key_stop] = False
        st.info("ƒê√£ reset tr·∫°ng th√°i d·ª´ng.")

def recognize_faces_in_image(image_bgr, detector, recognizer, svc):
    """Detects and recognizes faces in a static image."""
    st.info("B·∫Øt ƒë·∫ßu recognize_faces_in_image...")
    if not all([detector, recognizer, svc]):
        st.error("Models ch∆∞a ƒë∆∞·ª£c t·∫£i cho x·ª≠ l√Ω ·∫£nh.")
        return image_bgr

    output_image = image_bgr.copy()
    height, width, _ = output_image.shape

    try:
        # Set input size for detector
        detector.setInputSize([width, height])
        st.info(f"ƒê·∫∑t InputSize cho detector (·∫£nh): {width}x{height}")
        faces = detector.detect(image_bgr)
        st.info(f"K·∫øt qu·∫£ detect: {type(faces)}") # In ra ki·ªÉu d·ªØ li·ªáu c·ªßa faces
        if isinstance(faces, tuple) and len(faces) > 1 and faces[1] is not None:
            num_detected = len(faces[1])
            num_to_process = min(num_detected, 5)  # L·∫•y t·ªëi ƒëa 5
            st.success(f"Ph√°t hi·ªán {num_detected} khu√¥n m·∫∑t. ƒêang x·ª≠ l√Ω {num_to_process} khu√¥n m·∫∑t.")

            for face_info in faces[1][:num_to_process]:  # Ch·ªâ l·∫∑p qua t·ªëi ƒëa 5 khu√¥n m·∫∑t ƒë·∫ßu ti√™n
                 try:
                     # Align, Feature, Predict (gi·ªëng process_video_stream)
                     face_align = recognizer.alignCrop(image_bgr, face_info)
                     face_feature = recognizer.feature(face_align)
                     test_predict = svc.predict(face_feature)
                     # --- √Åp d·ª•ng logic confidence ---
                     result = "Error"
                     color = (0, 0, 0)
                     confidence_threshold = 0.1
                     if hasattr(svc, "decision_function"):
                         try:
                             confidence_score = np.max(svc.decision_function(face_feature))
                             if confidence_score < confidence_threshold:
                                 result = "Cannot Recognize!"
                                 color = (128, 128, 128)
                             elif 0 <= test_predict[0] < len(MY_DICT):
                                 result = MY_DICT[test_predict[0]]
                                 color = COLORS[test_predict[0] % len(COLORS)]
                             else:
                                 result = "Unknown Index"
                                 color = (0, 0, 255)
                         except Exception as e_conf:
                             result = "Confidence Error"
                             color = (0, 0, 255)
                     else:
                         if 0 <= test_predict[0] < len(MY_DICT):
                             result = MY_DICT[test_predict[0]]
                             color = COLORS[test_predict[0] % len(COLORS)]
                         else:
                             result = "Unknown"
                             color = (0, 0, 0)
                     # --- K·∫øt th√∫c logic confidence ---

                     coords = face_info[:4].astype(np.int32)
                     x1, y1, w, h = coords[0], coords[1], coords[2], coords[3]
                     cv.rectangle(output_image, (x1, y1), (x1+w, y1+h), color, 3)
                     text_y = y1 - 10 if y1 > 10 else y1 + 15

                     # Get text size.
                     text_size = cv.getTextSize(result, cv.FONT_HERSHEY_SIMPLEX, 0.7, 1)
                     dim, baseline = text_size[0], text_size[1]
                     cv.rectangle(output_image, (x1 - 5, text_y+10), (x1 + dim[0], text_y + baseline - 35), color, cv.FILLED)
                     # Display text inside the rectangle.
                     cv.putText(output_image, result, (x1, text_y), cv.FONT_HERSHEY_SIMPLEX, 0.6, (0,0,0), 1, cv.LINE_AA)

                     #cv.putText(output_image, result, (x1, text_y), cv.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 3, cv.LINE_AA)
                 except Exception as e_recog_img:
                     st.warning(f"L·ªói khi x·ª≠ l√Ω m·ªôt khu√¥n m·∫∑t trong ·∫£nh: {e_recog_img}")
                     try:
                          coords = face_info[:4].astype(np.int32)
                          x1, y1, w, h = coords[0], coords[1], coords[2], coords[3]
                          cv.rectangle(output_image, (x1, y1), (x1+w, y1+h), (0,0,255), 1)
                     except: pass
        elif isinstance(faces, tuple) and len(faces) > 1 and faces[1] is None:
             st.info("Kh√¥ng ph√°t hi·ªán th·∫•y khu√¥n m·∫∑t n√†o trong ·∫£nh.")
        else:
             st.warning(f"ƒê·ªãnh d·∫°ng k·∫øt qu·∫£ detect kh√¥ng nh∆∞ mong ƒë·ª£i: {type(faces)}")


    except Exception as e_detect_img:
        st.error(f"L·ªói trong qu√° tr√¨nh detect khu√¥n m·∫∑t tr√™n ·∫£nh: {e_detect_img}")
        import traceback
        st.code(traceback.format_exc())

    st.info("K·∫øt th√∫c recognize_faces_in_image.")
    return output_image

# Ch∆∞∆°ng tr√¨nh ch√≠nh
st.title("Nh·∫≠n d·∫°ng khu√¥n m·∫∑t 5 ng∆∞·ªùi üôÇ")
svc_model = load_svm_model(SVM_MODEL_PATH)
detector_model = load_face_detector(DETECTOR_MODEL_PATH)
recognizer_model = load_face_recognizer(RECOGNIZER_MODEL_PATH)

tab1, tab2, tab3 = st.tabs(["WebCam", "Video File", "Image"])

# Webcam
with tab1:
    st.header("S·ª≠ d·ª•ng Webcam üìπ")
    run_realtime = st.button("Start Real-Time Detection", key="start_realtime")
    if run_realtime:
        # ƒê·∫∑t l·∫°i tr·∫°ng th√°i d·ª´ng tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
        st.session_state['stop_processing_0'] = False
        st.info("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω Real-Time...")
        process_video_stream(0)

# Video File
with tab2:
    st.header("X·ª≠ l√Ω t·ª´ File Video üé¨")
    default_video_path = Path("./images/video_predict.mp4")

    if default_video_path.is_file():
        st.write("Xem tr∆∞·ªõc video m·∫∑c ƒë·ªãnh:")
        try:
            video_file = open(default_video_path, 'rb')
            video_bytes = video_file.read()
            st.video(video_bytes)
            run_default = st.button("Start Processing Default Video", key="start_default_video")
            if run_default:
                st.session_state[f'stop_processing_{str(default_video_path)}'] = False
                st.info("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video m·∫∑c ƒë·ªãnh...")
                process_video_stream(str(default_video_path))
        except Exception as e:
            st.error(f"Error reading or displaying default video: {e}")
    else:
        st.warning(f"Default video not found at: {default_video_path}")

    st.divider()
    uploaded_file = st.file_uploader("Ho·∫∑c t·∫£i l√™n file video kh√°c", type=["mp4", "avi", "mov", "mkv"], key="file_uploader")
    if uploaded_file is not None:
        temp_video_path = Path("./temp_video_uploaded") / uploaded_file.name
        temp_video_path.parent.mkdir(parents=True, exist_ok=True)
        with open(temp_video_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        st.write("Xem tr∆∞·ªõc video ƒë√£ t·∫£i l√™n:")
        st.video(uploaded_file)
        run_uploaded = st.button("Start Processing Uploaded Video", key="start_uploaded_video")
        if run_uploaded:
            st.session_state[f'stop_processing_{str(temp_video_path)}'] = False
            st.info("B·∫Øt ƒë·∫ßu x·ª≠ l√Ω video t·∫£i l√™n...")
            process_video_stream(str(temp_video_path))

# Image
with tab3:
    st.header("X·ª≠ l√Ω t·ª´ ·∫¢nh Tƒ©nh üì∑")
    uploaded_image_file = st.file_uploader(
        "T·∫£i l√™n m·ªôt h√¨nh ·∫£nh",
        type=["jpg", "jpeg", "png", "bmp"],
        key="face_image_uploader"
    )

    if uploaded_image_file is not None:
        if not all([svc_model, detector_model, recognizer_model]):
             st.error("M·ªôt ho·∫∑c nhi·ªÅu model c·∫ßn thi·∫øt ch∆∞a ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng. Kh√¥ng th·ªÉ x·ª≠ l√Ω ·∫£nh.")
        else:
            col1_img, col2_img = st.columns(2)
            try:
                # ƒê·ªçc ·∫£nh s·ª≠ d·ª•ng PIL
                image_pil = Image.open(uploaded_image_file)
                with col1_img:
                     st.subheader("·∫¢nh g·ªëc")
                     st.image(image_pil, caption=f"·∫¢nh t·∫£i l√™n: {uploaded_image_file.name}", use_container_width=True)

                # Convert PIL Image to OpenCV BGR format
                image_bgr = cv.cvtColor(np.array(image_pil), cv.COLOR_RGB2BGR)

                with st.spinner("ƒêang nh·∫≠n d·∫°ng khu√¥n m·∫∑t tr√™n ·∫£nh..."):
                     image_result_bgr = recognize_faces_in_image(
                         image_bgr,
                         detector=detector_model,
                         recognizer=recognizer_model,
                         svc=svc_model
                     )

                with col2_img:
                     st.subheader("K·∫øt qu·∫£ nh·∫≠n d·∫°ng")
                     image_result_rgb = cv.cvtColor(image_result_bgr, cv.COLOR_BGR2RGB)
                     st.image(image_result_rgb, caption="·∫¢nh ƒë√£ x·ª≠ l√Ω", use_container_width=True)

            except Exception as e_img:
                st.error(f"ƒê√£ x·∫£y ra l·ªói khi ƒë·ªçc ho·∫∑c x·ª≠ l√Ω ·∫£nh: {e_img}")
                import traceback
                st.code(traceback.format_exc())
    else:
        st.info("Vui l√≤ng t·∫£i l√™n m·ªôt h√¨nh ·∫£nh trong tab n√†y ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n d·∫°ng.")

